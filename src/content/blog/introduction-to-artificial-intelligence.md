---
title: Introduction to Artificial Intelligence
ogImage: https://i.imgur.com/GC3eWj5.png
tags:
  - artificial intelligence
pubDatetime: 2024-07-01T10:00:00.169Z
featured: false
draft: true
description: Learning Artificial Intelligence - Week 1
---

Computers were invented by Charles Baggage to perform defined procedures or algortithims. External factors in technology have changed, but the basic principle and utility of computers remain the same.

Things begin to get a bit abstract if we do not know each step in a sequenece to give to a computer though. What happens then? Artificial Intelligence (AI) can be us solve this problem.

## Weak vs Strong AI

I think it will be helpful to split two types of the AI we might see or hear about. Weak AI is designed to perform a narrow task, such as facial recognition. Strong AI is designed to perform any intellectual task that a human can do.

Weak AI is far more common in our normal day to day. Some common examples include:

- Siri
- Spotify recommendations
- Customer service chat bots

Strong AI can be thought of as a goal that the AI industry is striving towards. A strong AI could reason, understand, and learn just like a human could.

## Intellgence

What does intelligance mean to you? Critical or abstract thought? Superior awareness about yourself or the world around you? The ability to learn and adapt?

The irony here is that the definition of Intelligence is a bit of a mystery itself. It's hard to find a defintion that can be set as a standard. No standarized test or metric system can be used to measure or quaniify this concept in humans or any living organism.

Alan Turing created a way to potentially measure intelligence. The way his test worked was to have a human judge a conversation between a human and a machine. If the judge could not tell the difference between the two, the machine was considered intelligent.

## Thinking human

How would a computer think, act, or learn like you or I would? Conceptually, this starts with how humans think and understand. How can you tell the difference between a red and green? You don't consiously think about this, you just know. We learned this at some point, and a computer has to learn this as well.

The way computers learn is through models. A model is a representation of a system that is used to make predictions or decisions. The model is trained on data, and then used to make predictions on new data.

There are two ways to approach this problem:

1. **Top-down Approach: Symbolic Reasoning**:

- Try to model our reasoning process
- We follow thoughts when we reason, try to formalize this process for a computer
- Knowledge representation and reasoning are the two main components

Imagine you go see a doctor, and they discover that you have a fever. Once they know this, they know that inflammation is a possible cause. By reaching this conclusion, the doctor applied a large set of rules to a certain behavior that helped them reach a decision.

2 **Bottom-up Approach: Neural Networks**:

- Model off of a simple element found in the human brain, a neuron
- By constructing an artificial neural network in a computer, we can teach the computer to solve problems by giving examples for those problems and solutions

A way to think about this process is how you would go about teaching a newborn baby things. A lot of this learning is done oberservationally; inadverantly being shown how to do things.

## History

Artificial Intelligence may seem like a newer idea and it more in vogue than ever before, however, its origin dates back almost 70 years. The term was first coined by John McCarthy in 1956. Back then, Top Down, or Symbolic Reasoning was the predominant approach, as many successes stemmed from creating expert systems (computers that acted as an expert in a particular field with problem domains). This system did not scale well though due to the fact that feeding these models updated data from experts in a field was quite cumbersome and clunky. Because of this, advancements in AI slowed quite a bit and ultimately led to what is commonly referred to as the "AI Winter" in the 70s.

As the technology advanced over the course of a few decades, computer resources continually got cheaper. Data became more regularly accessible as well, which helped stoke to fire of the neural network effort. Due to cheaper resources and greater data availability, neural networks began to advance much more rapidly, most often showcasing their ability to understand human speech and behavior.

In modern day, neural networks is used as a interchangeable term for AI because many of the AI successes you see or hear about, are based on them.
